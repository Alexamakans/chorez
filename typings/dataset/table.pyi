"""
This type stub file was generated by pyright.
"""

log = ...
class Table:
    """Represents a table in a database and exposes common operations."""
    PRIMARY_DEFAULT = ...
    def __init__(self, database, table_name, primary_id=..., primary_type=..., primary_increment=..., auto_create=...) -> None:
        """Initialise the table from database schema."""
        ...
    
    @property
    def exists(self): # -> bool:
        """Check to see if the table currently exists in the database."""
        ...
    
    @property
    def table(self): # -> Table | None:
        """Get a reference to the table, which may be reflected or created."""
        ...
    
    @property
    def columns(self): # -> list[Any]:
        """Get a listing of all columns that exist in the table."""
        ...
    
    def has_column(self, column): # -> bool:
        """Check if a column with the given name exists on this table."""
        ...
    
    def insert(self, row, ensure=..., types=...): # -> Literal[True]:
        """Add a ``row`` dict by inserting it into the table.

        If ``ensure`` is set, any of the keys of the row are not
        table columns, they will be created automatically.

        During column creation, ``types`` will be checked for a key
        matching the name of a column to be created, and the given
        SQLAlchemy column type will be used. Otherwise, the type is
        guessed from the row value, defaulting to a simple unicode
        field.
        ::

            data = dict(title='I am a banana!')
            table.insert(data)

        Returns the inserted row's primary key.
        """
        ...
    
    def insert_ignore(self, row, keys, ensure=..., types=...): # -> bool:
        """Add a ``row`` dict into the table if the row does not exist.

        If rows with matching ``keys`` exist no change is made.

        Setting ``ensure`` results in automatically creating missing columns,
        i.e., keys of the row are not table columns.

        During column creation, ``types`` will be checked for a key
        matching the name of a column to be created, and the given
        SQLAlchemy column type will be used. Otherwise, the type is
        guessed from the row value, defaulting to a simple unicode
        field.
        ::

            data = dict(id=10, title='I am a banana!')
            table.insert_ignore(data, ['id'])
        """
        ...
    
    def insert_many(self, rows, chunk_size=..., ensure=..., types=...): # -> None:
        """Add many rows at a time.

        This is significantly faster than adding them one by one. Per default
        the rows are processed in chunks of 1000 per commit, unless you specify
        a different ``chunk_size``.

        See :py:meth:`insert() <dataset.Table.insert>` for details on
        the other parameters.
        ::

            rows = [dict(name='Dolly')] * 10000
            table.insert_many(rows)
        """
        ...
    
    def update(self, row, keys, ensure=..., types=..., return_count=...): # -> Literal[0] | None:
        """Update a row in the table.

        The update is managed via the set of column names stated in ``keys``:
        they will be used as filters for the data to be updated, using the
        values in ``row``.
        ::

            # update all entries with id matching 10, setting their title
            # columns
            data = dict(id=10, title='I am a banana!')
            table.update(data, ['id'])

        If keys in ``row`` update columns not present in the table, they will
        be created based on the settings of ``ensure`` and ``types``, matching
        the behavior of :py:meth:`insert() <dataset.Table.insert>`.
        """
        ...
    
    def update_many(self, rows, keys, chunk_size=..., ensure=..., types=...): # -> None:
        """Update many rows in the table at a time.

        This is significantly faster than updating them one by one. Per default
        the rows are processed in chunks of 1000 per commit, unless you specify
        a different ``chunk_size``.

        See :py:meth:`update() <dataset.Table.update>` for details on
        the other parameters.
        """
        ...
    
    def upsert(self, row, keys, ensure=..., types=...): # -> Literal[True]:
        """An UPSERT is a smart combination of insert and update.

        If rows with matching ``keys`` exist they will be updated, otherwise a
        new row is inserted in the table.
        ::

            data = dict(id=10, title='I am a banana!')
            table.upsert(data, ['id'])
        """
        ...
    
    def upsert_many(self, rows, keys, chunk_size=..., ensure=..., types=...): # -> None:
        """
        Sorts multiple input rows into upserts and inserts. Inserts are passed
        to insert and upserts are updated.

        See :py:meth:`upsert() <dataset.Table.upsert>` and
        :py:meth:`insert_many() <dataset.Table.insert_many>`.
        """
        ...
    
    def delete(self, *clauses, **filters): # -> Literal[False]:
        """Delete rows from the table.

        Keyword arguments can be used to add column-based filters. The filter
        criterion will always be equality:
        ::

            table.delete(place='Berlin')

        If no arguments are given, all records are deleted.
        """
        ...
    
    def create_column(self, name, type, **kwargs): # -> None:
        """Create a new column ``name`` of a specified type.
        ::

            table.create_column('created_at', db.types.datetime)

        `type` corresponds to an SQLAlchemy type as described by
        `dataset.db.Types`. Additional keyword arguments are passed
        to the constructor of `Column`, so that default values, and
        options like `nullable` and `unique` can be set.
        ::

            table.create_column('key', unique=True, nullable=False)
            table.create_column('food', default='banana')
        """
        ...
    
    def create_column_by_example(self, name, value): # -> None:
        """
        Explicitly create a new column ``name`` with a type that is appropriate
        to store the given example ``value``.  The type is guessed in the same
        way as for the insert method with ``ensure=True``.
        ::

            table.create_column_by_example('length', 4.2)

        If a column of the same name already exists, no action is taken, even
        if it is not of the type we would have created.
        """
        ...
    
    def drop_column(self, name): # -> None:
        """
        Drop the column ``name``.
        ::

            table.drop_column('created_at')

        """
        ...
    
    def drop(self): # -> None:
        """Drop the table from the database.

        Deletes both the schema and all the contents within it.
        """
        ...
    
    def has_index(self, columns): # -> bool:
        """Check if an index exists to cover the given ``columns``."""
        ...
    
    def create_index(self, columns, name=..., **kw): # -> None:
        """Create an index to speed up queries on a table.

        If no ``name`` is given a random name is created.
        ::

            table.create_index(['name', 'country'])
        """
        ...
    
    def find(self, *_clauses, **kwargs): # -> Iterator[Any] | ResultIter:
        """Perform a simple search on the table.

        Simply pass keyword arguments as ``filter``.
        ::

            results = table.find(country='France')
            results = table.find(country='France', year=1980)

        Using ``_limit``::

            # just return the first 10 rows
            results = table.find(country='France', _limit=10)

        You can sort the results by single or multiple columns. Append a minus
        sign to the column name for descending order::

            # sort results by a column 'year'
            results = table.find(country='France', order_by='year')
            # return all rows sorted by multiple columns (descending by year)
            results = table.find(order_by=['country', '-year'])

        You can also submit filters based on criteria other than equality,
        see :ref:`advanced_filters` for details.

        To run more complex queries with JOINs, or to perform GROUP BY-style
        aggregation, you can also use :py:meth:`db.query() <dataset.Database.query>`
        to run raw SQL queries instead.
        """
        ...
    
    def find_one(self, *args, **kwargs): # -> Any | row_type | None:
        """Get a single result from the table.

        Works just like :py:meth:`find() <dataset.Table.find>` but returns one
        result, or ``None``.
        ::

            row = table.find_one(country='United States')
        """
        ...
    
    def count(self, *_clauses, **kwargs): # -> Literal[0]:
        """Return the count of results for the given filter set."""
        ...
    
    def __len__(self): # -> Literal[0]:
        """Return the number of rows in the table."""
        ...
    
    def distinct(self, *args, **_filter): # -> Iterator[Any]:
        """Return all the unique (distinct) values for the given ``columns``.
        ::

            # returns only one row per year, ignoring the rest
            table.distinct('year')
            # works with multiple columns, too
            table.distinct('year', 'country')
            # you can also combine this with a filter
            table.distinct('year', country='China')
        """
        ...
    
    all = ...
    def __iter__(self): # -> Iterator[Any] | ResultIter:
        """Return all rows of the table as simple dictionaries.

        Allows for iterating over all rows in the table without explicitly
        calling :py:meth:`find() <dataset.Table.find>`.
        ::

            for row in table:
                print(row)
        """
        ...
    
    def __repr__(self): # -> LiteralString:
        """Get table representation."""
        ...
    


